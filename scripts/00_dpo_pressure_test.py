# scripts/00_dpo_pressure_test.py

import torch
from datasets import Dataset
from peft import LoraConfig
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import DPOTrainer, DPOConfig

def run_dpo_pressure_test():
    """
    ä¸€ä¸ªæœ€å°åŒ–çš„DPOè®­ç»ƒè„šæœ¬ï¼Œç”¨äºæµ‹è¯•åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„å¯è¡Œæ€§ã€‚
    æ­¤ç‰ˆæœ¬ä¸ä½¿ç”¨é‡åŒ–ï¼Œç›´æ¥æµ‹è¯•RTX 4060çš„8GBæ˜¾å­˜æé™ã€‚
    """
    print("--- å¼€å§‹DPOæé™å‹åŠ›æµ‹è¯• (æ— é‡åŒ–ç‰ˆæœ¬) ---")

    # 1. æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½
    model_name = "Qwen/Qwen2-7B-Instruct"
    print(f"åŠ è½½æ¨¡å‹: {model_name}")

    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ (æ— é‡åŒ–)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.bfloat16,  # ä½¿ç”¨bfloat16ä»¥èŠ‚çœæ˜¾å­˜
        low_cpu_mem_usage=True,      # å¯ç”¨ä½CPUå†…å­˜ä½¿ç”¨
        trust_remote_code=True,
    )
    
    # æ‰‹åŠ¨ç§»åŠ¨åˆ°GPU
    print("å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU...")
    model = model.to("cuda")
    print(f"æ¨¡å‹ç°åœ¨ä½äº: {next(model.parameters()).device}")
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    
    # Qwen2 tokenizeræ²¡æœ‰é»˜è®¤çš„pad_tokenï¼Œæˆ‘ä»¬å°†å…¶è®¾ç½®ä¸ºeos_token
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    print("æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½å®Œæ¯•ã€‚")

    # 2. åˆ›å»ºä¸€ä¸ªè™šå‡çš„æœ€å°åŒ–æ•°æ®é›†
    print("åˆ›å»ºè™šå‡æ•°æ®é›†...")
    dummy_data = {
        'prompt': ["Tell me a story about a brave knight."],
        'chosen': ["The brave knight fought the dragon and saved the princess."],
        'rejected': ["The knight was scared and ran away."]
    }
    dummy_dataset = Dataset.from_dict(dummy_data)
    print("æ•°æ®é›†åˆ›å»ºå®Œæ¯•ã€‚")
    
    # 3. LoRAé…ç½®
    peft_config = LoraConfig(
        r=16,
        lora_alpha=32,
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules="all-linear",
    )
    
    # 4. DPOè®­ç»ƒå‚æ•°é…ç½®
    dpo_config = DPOConfig(
        output_dir="./dpo_test_output",
        per_device_train_batch_size=1,
        gradient_accumulation_steps=1,
        learning_rate=1e-5,
        logging_steps=1,
        max_steps=2, # åªè®­ç»ƒ2æ­¥ï¼Œè¶³ä»¥éªŒè¯æ˜¯å¦OOM
        save_strategy="no", # ä¸ä¿å­˜æ¨¡å‹
        report_to="none", # å…³é—­wandbç­‰æŠ¥å‘Š
        beta=0.1,
        max_prompt_length=512,
        max_length=1024,
    )

    print("åˆå§‹åŒ–DPOTrainer...")
    # 5. åˆå§‹åŒ–DPOTrainer
    trainer = DPOTrainer(
        model=model,
        ref_model=None, # TRLä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬åˆ›å»ºå‚è€ƒæ¨¡å‹
        args=dpo_config,
        train_dataset=dummy_dataset,
        processing_class=tokenizer,
        peft_config=peft_config,
    )
    print("DPOTraineråˆå§‹åŒ–å®Œæ¯•ã€‚")

    # 6. å¼€å§‹è®­ç»ƒï¼
    print("\n--- å¼€å§‹è®­ç»ƒï¼Œè¯·å¯†åˆ‡å…³æ³¨æ˜¾å­˜å ç”¨ ---")
    print("å¯ä»¥åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£è¿è¡Œ 'nvidia-smi' æ¥ç›‘æ§GPUã€‚")
    
    try:
        trainer.train()
        print("\n--- è®­ç»ƒæ­¥éª¤æˆåŠŸå®Œæˆï¼---")
        print("ğŸš€ ç»“è®ºï¼šDPOè®­ç»ƒåœ¨å½“å‰ç¡¬ä»¶å’Œé…ç½®ä¸‹æ˜¯å¯è¡Œçš„ï¼é¡¹ç›®æ ¸å¿ƒé£é™©å·²è§£é™¤ã€‚")
        print("ğŸ’¡ é‡è¦ï¼šè¿™æ˜¯åœ¨æ— é‡åŒ–çš„æƒ…å†µä¸‹æˆåŠŸï¼Œè¯´æ˜æˆ‘ä»¬çš„ç¡¬ä»¶å®Œå…¨æ»¡è¶³è¦æ±‚ï¼")
    
    except torch.cuda.OutOfMemoryError:
        print("\n--- æ•è·åˆ°CUDA OutOfMemoryErrorï¼---")
        print("âŒ ç»“è®ºï¼šåœ¨å½“å‰é…ç½®ä¸‹ï¼ŒQwen2-7Bæ¨¡å‹çš„DPOè®­ç»ƒæ˜¾å­˜ä¸è¶³ã€‚")
        print("ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼šæˆ‘ä»¬éœ€è¦å¯ç”¨é‡åŒ–æˆ–åˆ‡æ¢åˆ°æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚Qwen2-1.5Bï¼‰ã€‚")
    
    except Exception as e:
        print(f"\n--- å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{e} ---")
        print("âŒ ç»“è®ºï¼šæµ‹è¯•æœªèƒ½æˆåŠŸï¼Œéœ€è¦è°ƒè¯•ã€‚è¯·å°†å®Œæ•´é”™è¯¯ä¿¡æ¯æŠ¥å‘Šã€‚")

if __name__ == "__main__":
    run_dpo_pressure_test() 